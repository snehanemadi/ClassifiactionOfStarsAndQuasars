{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.15126050420167%\n",
      "class 1 accuracy: 96.30252100840336\n",
      "class 0 accuracy: 100.0\n",
      "accuracy:98.15126050420167\n",
      "recall:96.30252100840336\n",
      "precision:100.0\n",
      "error rate:1.848739495798327\n"
     ]
    }
   ],
   "source": [
    "#python 3 implementation\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('cat3.csv')\n",
    "data=data.drop(['id','galex_objid','sdss_objid','spectrometric_redshift','pred'],axis=1)\n",
    "\n",
    "from sklearn.utils import resample\n",
    "class0= data[data['class']==0]#minority\n",
    "class1= data[data['class']==1]#majority\n",
    "class0_upsampled = resample(class0,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(class1), # match number in majority class\n",
    "                          random_state=123) # reproducible results\n",
    "upsampled = pd.concat([class1, class0_upsampled])\n",
    "\n",
    "\n",
    "#data.head()\n",
    "train_dataset=upsampled.values.tolist()\n",
    "\n",
    "d1=pd.read_csv('cat1.csv')\n",
    "d1=d1.drop(['id','galex_objid','sdss_objid','spectrometric_redshift','pred'],axis=1)\n",
    "#print(d1.shape)\n",
    "#d1.head()\n",
    "\n",
    "from sklearn.utils import resample\n",
    "class0= d1[d1['class']==0]#minority\n",
    "class1= d1[d1['class']==1]#majority\n",
    "class0_upsampled1 = resample(class0,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(class1), # match number in majority class\n",
    "                          random_state=123) # reproducible results\n",
    "upsampled1 = pd.concat([class1, class0_upsampled1])\n",
    "\n",
    "#data.head()\n",
    "test_dataset=upsampled1.values.tolist()\n",
    "#print(len(test_dataset))\n",
    "#print(test_dataset[0:2])\n",
    "\n",
    "import math\n",
    "# square root of the sum of the squared differences between the two arrays of numbers\n",
    "def euclideanDistance(instance1, instance2, length):\n",
    "    distance = 0\n",
    "    for x in range(length):\n",
    "        #print(instance1[x])\n",
    "        #print(instance2[x])\n",
    "        if(x!=12):\n",
    "            #print(instance1[x])\n",
    "            #print(instance2[x])\n",
    "            distance += pow((float(instance1[x]) - float(instance2[x])), 2)\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "def confusion_matrix(act,pred):\n",
    "    tp =0\n",
    "    fp =0\n",
    "    tn =0\n",
    "    fn =0\n",
    "    l0 = 0\n",
    "    l1 =0\n",
    "    for i in range(len(act)):\n",
    "        if(act[i]==0):\n",
    "            l0 += 1\n",
    "        elif(act[i]==1):\n",
    "            l1 += 1\n",
    "        if(act[i]==1 and pred[i]==1):\n",
    "            tp += 1\n",
    "        elif(act[i]==1 and pred[i]==0):\n",
    "            fn += 1\n",
    "        elif(act[i]==0 and pred[i]==1):\n",
    "            fp += 1\n",
    "        elif(act[i]==0 and pred[i]==0):\n",
    "            tn += 1\n",
    "    print(\"class 1 accuracy:\",((tp/l1)*100))\n",
    "    print(\"class 0 accuracy:\",((tn/l0)*100))\n",
    "    accuracy = ((tp+tn)/(tp+tn+fp+fn))*100\n",
    "    recall = ((tp)/(tp+fn))*100\n",
    "    precision = ((tp) / (tp+fp))*100\n",
    "    a=2*(recall)*(precision)\n",
    "    b=(recall+precision)\n",
    "    f_score = (a / b)*100\n",
    "    error_rate = 100-accuracy\n",
    "    print(\"accuracy:\" + repr(accuracy))\n",
    "    print(\"recall:\" + repr(recall))\n",
    "    print(\"precision:\" + repr(precision))\n",
    "    #print(\"f-score:\" + repr(f_score))\n",
    "    print(\"error rate:\" + repr(error_rate))\n",
    "    \n",
    "\n",
    "import operator\n",
    "#distances = []\n",
    "def getNeighbors(trainingSet, testInstance, k):\n",
    "    distances = []\n",
    "    length = len(testInstance)\n",
    "    for x in range(len(trainingSet)):\n",
    "        dist = euclideanDistance(testInstance, trainingSet[x], length)\n",
    "        distances.append((trainingSet[x], dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors\n",
    "\n",
    "  \n",
    "\n",
    "def getResponse(neighbors):\n",
    "    classVotes = {}\n",
    "    classVotes['0']=0\n",
    "    classVotes['1']=0\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x][12]\n",
    "        #print(response)\n",
    "        if response == 0.0:\n",
    "            classVotes['0'] += 1\n",
    "        else:\n",
    "            classVotes['1'] += 1\n",
    "    sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    #print(sortedVotes)\n",
    "    return float(sortedVotes[0][0])\n",
    "\n",
    "\n",
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        #print(predictions[x])\n",
    "        #print(testSet[x][14])\n",
    "        if testSet[x][12] == float(predictions[x]):\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0\n",
    "\n",
    "predictions=[]\n",
    "\n",
    "k = 7\n",
    "\n",
    "for x in range(len(test_dataset)):\n",
    "    neighbors = getNeighbors(train_dataset, test_dataset[x], k)\n",
    "    result = getResponse(neighbors)\n",
    "    predictions.append(result)\n",
    "    #print('> predicted=' + repr(result) + ', actual=' + repr(test_dataset[x][12]))\n",
    "    \n",
    "\n",
    "\n",
    "accuracy = getAccuracy(test_dataset, predictions)\n",
    "print('Accuracy: ' + repr(accuracy) + '%')\n",
    "actual = []\n",
    "for i in range(len(test_dataset)):\n",
    "    actual.append(test_dataset[i][12])\n",
    "\n",
    "results = confusion_matrix(actual, predictions) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
