{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [93.65598430346633, 95.16023544800524, 93.5251798561151, 94.6370176586004, 94.44081098757357]\n",
      "Each Fold accuracy:93.65598430346633\n",
      "Each Fold accuracy:95.16023544800524\n",
      "Each Fold accuracy:93.5251798561151\n",
      "Each Fold accuracy:94.6370176586004\n",
      "Each Fold accuracy:94.44081098757357\n",
      "Mean Accuracy: 94.284%\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import csv\n",
    "from random import randrange\n",
    "import pandas as pd\n",
    "import math\n",
    "import operator\n",
    "from sklearn.utils import resample\n",
    "\n",
    "#cross-validating cat3.csv with five folds \n",
    "data=pd.read_csv('cat3.csv')\n",
    "data=data.drop(['id','spectrometric_redshift','pred'],axis=1)\n",
    "#data=data.drop(['id','spectrometric_redshift','pred'],axis=1)\n",
    "\n",
    "#Upsampling stars since cat3.csv has less instances of stars in comparison of quesars\n",
    "#class 0 indicates stars and class 1 indicates quesars\n",
    "\n",
    "class0= data[data['class']==0]\n",
    "class1= data[data['class']==1]\n",
    "class0_upsampled = resample(class0,replace=True,n_samples=len(class1),random_state=123) \n",
    "upsampled = pd.concat([class1, class0_upsampled])\n",
    "dataset=upsampled.values.tolist()\n",
    "train = dataset\n",
    "\n",
    "#function to calculate distance, ignoring the column \"15\" since it is the class(i.e to be predicted) column in the dataset \n",
    "def euclideanDistance(i1, i2, length):\n",
    "    dist = 0\n",
    "    for i in range(length):\n",
    "        if(i!=14):\n",
    "            dist += pow((float(i1[i]) - float(i2[i])), 2)\n",
    "    return math.sqrt(dist)\n",
    "\n",
    "#function to get the nearest neighbours\n",
    "def getneighbors(trainingSet, testInstance, k):\n",
    "    distances = []\n",
    "    length = len(testInstance)\n",
    "    for x in range(len(trainingSet)):\n",
    "        dist = euclideanDistance(testInstance, trainingSet[x], length)\n",
    "        distances.append((trainingSet[x], dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    n = []\n",
    "    for x in range(k):\n",
    "        n.append(distances[x][0])\n",
    "    return n\n",
    "\n",
    "  \n",
    "\n",
    "def votes(n):\n",
    "    neigh_votes = {}\n",
    "    neigh_votes['0']=0\n",
    "    neigh_votes['1']=0\n",
    "    for x in range(len(n)):\n",
    "        response = n[x][14]\n",
    "\n",
    "        if response == 0.0:\n",
    "            neigh_votes['0'] += 1\n",
    "        else:\n",
    "            neigh_votes['1'] += 1\n",
    "    sortedVotes = sorted(neigh_votes.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "    return float(sortedVotes[0][0])\n",
    "\n",
    "\n",
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        if testSet[x][14] == float(predictions[x]):\n",
    "                correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0\n",
    "\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = dataset\n",
    "    fold_size = int(len(dataset_copy) / n_folds)\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "\n",
    "def knn_algo(train,test,k):\n",
    "    predictions=[]\n",
    "    for x in range(len(test)):\n",
    "\n",
    "        neighbors = getneighbors(train, test[x], k)\n",
    "\n",
    "        result = votes(neighbors)\n",
    "        predictions.append(result)\n",
    "\n",
    "    return predictions\n",
    "        \n",
    "    \n",
    "\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, k):\n",
    "    dataset_split = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for cur_fold in dataset_split:\n",
    "        train=list()\n",
    "        test_set = cur_fold\n",
    "        train_set = dataset_split.copy()\n",
    " \n",
    "        ind = train_set.index(cur_fold)\n",
    "        del(train_set[ind])\n",
    "        \n",
    "        for fold in train_set:\n",
    "            for row in fold:\n",
    "                train.append(row)\n",
    "        \n",
    "        \n",
    "        predictions = algorithm(train, test_set, k)\n",
    "\n",
    "        \n",
    "        accuracy = getAccuracy(test_set, predictions)\n",
    "        scores.append(accuracy)\n",
    "      \n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "k = 7\n",
    "n_folds = 5\n",
    "\n",
    "scores = evaluate_algorithm(train, knn_algo, n_folds, k)\n",
    "\n",
    "print('Scores: %s' % scores)\n",
    "for i in range(len(scores)):\n",
    "    print(\"Each Fold accuracy:\"+repr(scores[i]))\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
